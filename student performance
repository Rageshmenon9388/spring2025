{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":561,"sourceType":"datasetVersion","datasetId":251}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  Classifying Student Performance\n\n**Introduction**\n\nIn today’s data-driven schools, giving teachers clear early signals about which students are likely to excel or fall behind is crucial for timely support. In this project, we use a dataset of student demographics, study habits, attendance, and behavior indicators to build a simple, interpretable machine learning model that predicts whether a student will earn a high final grade (G3 ≥ 10) or not. By focusing on a transparent algorithm like Logistic Regression, our goal is to highlight the most influential factors such as study time, absences, and past performance so educators can understand the “why” behind each prediction and take targeted actions to help every learner succeed.\n\n**Objective:**  \nPredict whether a student will be a High Performer (final grade G3 ≥ 10) or Low Performer (G3 < 10) based on demographic, academic and behavioral features.\n\n**Dataset:**  \nThe `student‐mat.csv` file contains 395 student records with 33 features (e.g., study time, absences, alcohol consumption).\n\n**Pipeline Outline:**  \n Exploratory Data Analysis (EDA)  \n Data Cleaning & Feature Engineering  \n Feature Correlation Analysis  \n Model Training (Logistic Regression, Decision Tree, Random Forest)  \n Hyperparameter Tuning with GridSearchCV  \n Evaluation & Comparison  \n Conclusions & Next Steps\n","metadata":{}},{"cell_type":"markdown","source":"## Downloading the Dataset\n\nWe use the kagglehub library to fetch the latest version of the Student Alcohol Consumption dataset from Kaggle. \n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"uciml/student-alcohol-consumption\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:41:01.551343Z","iopub.execute_input":"2025-06-27T00:41:01.551632Z","iopub.status.idle":"2025-06-27T00:41:01.649184Z","shell.execute_reply.started":"2025-06-27T00:41:01.551613Z","shell.execute_reply":"2025-06-27T00:41:01.64828Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Library Imports & Data Loading\n\nWe begin by importing standard libraries for data handling, visualization, and modeling, then load the CSV into a DataFrame.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Load data\ndf = pd.read_csv('/kaggle/input/student-alcohol-consumption/student-mat.csv')\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:50:48.519644Z","iopub.execute_input":"2025-06-27T00:50:48.52043Z","iopub.status.idle":"2025-06-27T00:50:48.547919Z","shell.execute_reply.started":"2025-06-27T00:50:48.520398Z","shell.execute_reply":"2025-06-27T00:50:48.546884Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Exploratory Data Analysis\n\n **Basic structure:** number of rows, columns, data types, missing values.  \n\n","metadata":{}},{"cell_type":"code","source":"# 2.1 Structure & missing values\nprint(df.info())\nprint(df.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:52:00.480317Z","iopub.execute_input":"2025-06-27T00:52:00.480609Z","iopub.status.idle":"2025-06-27T00:52:00.49326Z","shell.execute_reply.started":"2025-06-27T00:52:00.480589Z","shell.execute_reply":"2025-06-27T00:52:00.492306Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" **Target distribution:** proportion of high vs. low performers.","metadata":{}},{"cell_type":"code","source":"# 2.2 Target distribution (create for plotting)\ndf['high_grade'] = (df['G3'] >= 10).astype(int)\nsns.countplot(x='high_grade', data=df)\nplt.title('High vs. Low Performers')\nplt.xlabel('High Performer (1) vs Low (0)')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:52:54.041903Z","iopub.execute_input":"2025-06-27T00:52:54.042277Z","iopub.status.idle":"2025-06-27T00:52:54.187316Z","shell.execute_reply.started":"2025-06-27T00:52:54.042249Z","shell.execute_reply":"2025-06-27T00:52:54.186367Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Feature distributions:** histograms for numerical, bar plots for categorical. ","metadata":{}},{"cell_type":"code","source":"# 2.3 Example: numeric feature distributions\nnumeric_cols = ['age', 'studytime', 'absences']\ndf[numeric_cols].hist(bins=15, figsize=(8,4))\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:53:18.785096Z","iopub.execute_input":"2025-06-27T00:53:18.785799Z","iopub.status.idle":"2025-06-27T00:53:19.264901Z","shell.execute_reply.started":"2025-06-27T00:53:18.785772Z","shell.execute_reply":"2025-06-27T00:53:19.263992Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Initial observations:** any standout trends.","metadata":{}},{"cell_type":"code","source":"# 2.4 Example: categorical feature bar plot\nsns.countplot(x='sex', hue='high_grade', data=df)\nplt.title('Performance by Sex')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:53:43.389868Z","iopub.execute_input":"2025-06-27T00:53:43.390209Z","iopub.status.idle":"2025-06-27T00:53:43.556586Z","shell.execute_reply.started":"2025-06-27T00:53:43.390181Z","shell.execute_reply":"2025-06-27T00:53:43.555668Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Data Cleaning & Preprocessing\n\n **Reload** the original data to be sure we haven’t mutated it in earlier cells.  \n **Create** the binary target `high_grade` (1 if G3 ≥ 10, else 0).  \n **Drop** the original grade columns (`G1`, `G2`, `G3`) only if they exist.  \n **One-hot encode** all categorical features.  \n **Split** into train/test sets (stratified on the target).  \n **Scale** all numeric features with `StandardScaler`.\n\n","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\n# Reload & preprocess\ndf = pd.read_csv('/kaggle/input/student-alcohol-consumption/student-mat.csv')\ndf['high_grade'] = (df['G3'] >= 10).astype(int)\n\ncols_to_drop = [c for c in ['G1','G2','G3'] if c in df.columns]\nprint(\"Dropped columns:\", cols_to_drop)\n\ndf.drop(columns=cols_to_drop, inplace=True)\nprint(\"Shape after drop:\", df.shape)\n\ndf = pd.get_dummies(df, drop_first=True)\nprint(\"Shape after encoding:\", df.shape)\n\nX = df.drop('high_grade', axis=1)\ny = df['high_grade']\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.20, random_state=42, stratify=y\n)\nprint(f\"Train shape: {X_train.shape} | Test shape: {X_test.shape}\")\n\nnum_cols = X.select_dtypes(include=['int64','float64']).columns\nscaler = StandardScaler()\nX_train.loc[:, num_cols] = scaler.fit_transform(X_train[num_cols])\nX_test.loc[:, num_cols]  = scaler.transform(X_test[num_cols])\n\ndisplay(X_train.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T01:00:21.579989Z","iopub.execute_input":"2025-06-27T01:00:21.580694Z","iopub.status.idle":"2025-06-27T01:00:21.664461Z","shell.execute_reply.started":"2025-06-27T01:00:21.580667Z","shell.execute_reply":"2025-06-27T01:00:21.66349Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Feature Correlation Analysis\n\nAssess pairwise correlations to identify multicollinearity and strong predictors.\n","metadata":{}},{"cell_type":"code","source":"# 4.1 Build correlation matrix on numeric features + target\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncorr_df = pd.concat([X_train[num_cols], y_train.reset_index(drop=True)], axis=1)\ncorr_matrix = corr_df.corr()\n\nplt.figure(figsize=(12,10))\nsns.heatmap(corr_matrix, cmap='coolwarm', center=0, annot=False)\nplt.title('Correlation Matrix: Numeric Features + Target')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T01:01:58.166494Z","iopub.execute_input":"2025-06-27T01:01:58.16681Z","iopub.status.idle":"2025-06-27T01:01:58.529061Z","shell.execute_reply.started":"2025-06-27T01:01:58.166786Z","shell.execute_reply":"2025-06-27T01:01:58.528146Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Baseline Model Training\n\nTrain initial classifiers without hyperparameter tuning to establish benchmarks:\n\n Logistic Regression  \n Decision Tree  \n Random Forest  \n","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n\nbaseline_models = {\n    'Logistic Regression': LogisticRegression(max_iter=500),\n    'Decision Tree': DecisionTreeClassifier(random_state=42),\n    'Random Forest': RandomForestClassifier(random_state=42)\n}\n\nfor name, model in baseline_models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    print(f\"{name} Accuracy: {acc:.4f}\")\n    print(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T01:02:22.226694Z","iopub.execute_input":"2025-06-27T01:02:22.226954Z","iopub.status.idle":"2025-06-27T01:02:22.632339Z","shell.execute_reply.started":"2025-06-27T01:02:22.226936Z","shell.execute_reply":"2025-06-27T01:02:22.631495Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Hyperparameter Tuning\n\nOptimize model performance using `GridSearchCV`:\n\n **Logistic Regression**: C  \n **Decision Tree**: max_depth, min_samples_split  \n **Random Forest**: n_estimators, max_depth  \n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'Logistic Regression': {\n        'C': [0.01, 0.1, 1, 10]\n    },\n    'Decision Tree': {\n        'max_depth': [None, 5, 10, 20],\n        'min_samples_split': [2, 5, 10]\n    },\n    'Random Forest': {\n        'n_estimators': [50, 100, 200],\n        'max_depth': [None, 5, 10]\n    }\n}\n\nbest_models = {}\nfor name, model in baseline_models.items():\n    grid = GridSearchCV(model, param_grid[name], cv=5, scoring='accuracy', n_jobs=-1)\n    grid.fit(X_train, y_train)\n    best_models[name] = grid.best_estimator_\n    print(f\"{name} best params: {grid.best_params_}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T01:03:28.871327Z","iopub.execute_input":"2025-06-27T01:03:28.872047Z","iopub.status.idle":"2025-06-27T01:03:35.868787Z","shell.execute_reply.started":"2025-06-27T01:03:28.872013Z","shell.execute_reply":"2025-06-27T01:03:35.867914Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Model Evaluation & Comparison\n\nEvaluate each tuned model on the test set:\n\nClassification report  \n\nConfusion matrix  \n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nfor name, model in best_models.items():\n    y_pred = model.predict(X_test)\n    print(f\"--- {name} ---\")\n    print(classification_report(y_test, y_pred))\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(5,4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(f'{name} Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T01:06:27.582301Z","iopub.execute_input":"2025-06-27T01:06:27.582954Z","iopub.status.idle":"2025-06-27T01:06:28.248546Z","shell.execute_reply.started":"2025-06-27T01:06:27.582931Z","shell.execute_reply":"2025-06-27T01:06:28.247677Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Key Findings**\n\nAcross all three algorithms, baseline performance hovered around 66–68 % accuracy, with Random Forest leading at 68.4 %. After hyperparameter tuning, Logistic Regression improved modestly to 68.4 % accuracy (up from 65.8 %), while Decision Tree remained at 66.0 % and Random Forest dipped slightly back to 66.0 %. In terms of class-specific performance, the tuned Logistic Regression model achieved the strongest balance for identifying high performers precision of 0.73 and recall of 0.85 (F1 = 0.78) and its weighted F1 of 0.66 edged out Decision Tree (0.65) and Random Forest (0.61). All models struggled to identify low performers (recall 0.35–0.38), but Logistic Regression still maintained the best precision (0.53) on that class.\n\n**Final Comparison & Reflection**\n\nFor deployment in a real-time school analytical tool, I recommend the tuned Logistic Regression model. It delivers the highest overall accuracy post-tuning, yields the best F1-score balance for detecting both high and low performers, and offers the interpretability crucial for educational stakeholders. Unlike tree-based methods, its coefficients provide clear insights into which factors (e.g., study time, absences, failures) most influence student outcomes. This transparency will help educators trust and act upon its predictions, while its stable performance reduces the risk of overfitting and simplifies future maintenance or retraining.\n\n**Conclusion**\n\nOur results show that a well-tuned Logistic Regression model gives the best mix of accuracy and clarity for spotting students likely to do well or struggle,its simple coefficients let teachers see exactly how factors like study time, absences, and past failures matter, and its light footprint means it’s easy to retrain as new grades come in; to catch even more at risk students, schools can layer in basic alerts (for example, flagging very low study hours) and bring in extra data like homework completion, then retrain the model periodically to keep its predictions sharp.","metadata":{}}]}